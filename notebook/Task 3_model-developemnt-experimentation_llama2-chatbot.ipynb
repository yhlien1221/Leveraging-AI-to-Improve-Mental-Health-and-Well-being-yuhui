{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5821,"status":"ok","timestamp":1749257145158,"user":{"displayName":"Yu-Hui Lien","userId":"16304015909641248327"},"user_tz":240},"id":"wKTFSxYf64Lz","outputId":"753b30a4-9ed3-462c-888b-a2ecab19f1f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["#!pip install -q transformers faiss-cpu sentence-transformers\n","#!pip install -U bitsandbytes\n","\n","!pip install -q streamlit ctransformers\n"]},{"cell_type":"code","source":["%%writefile app.py\n","# app.py\n","import streamlit as st\n","from ctransformers import AutoModelForCausalLM\n","\n","# 1) Load model using ctransformers\n","@st.cache_resource\n","def load_model():\n","    return AutoModelForCausalLM.from_pretrained(\n","        \"TheBloke/Llama-2-7B-Chat-GGML\",\n","        model_file=\"llama-2-7b-chat.ggmlv3.q4_0.bin\",  # You must download this model\n","        model_type=\"llama\",\n","        gpu_layers=32  # Adjust for your GPU\n","    )\n","\n","llm = load_model()\n","\n","# 2) Streamlit UI\n","st.title(\"üß† Mental Health Counselor Chatbot\")\n","st.caption(\"üí¨ Powered by ctransformers LLaMA-2\")\n","\n","if \"chat_history\" not in st.session_state:\n","    st.session_state.chat_history = []\n","\n","# Display previous chat\n","for role, msg in st.session_state.chat_history:\n","    with st.chat_message(role):\n","        st.markdown(msg)\n","\n","# New input\n","if user_input := st.chat_input(\"You:\"):\n","    st.chat_message(\"user\").markdown(user_input)\n","    st.session_state.chat_history.append((\"user\", user_input))\n","\n","    # Rebuild prompt\n","    MAX_HISTORY_TURNS = 4\n","    hist = st.session_state.chat_history[-MAX_HISTORY_TURNS*2:]\n","    prompt = \"\"\n","    for role, msg in hist:\n","        prompt += f\"{'User' if role=='user' else 'Bot'}: {msg}\\n\"\n","    prompt += \"Bot:\"\n","\n","    # Generate reply\n","    reply = llm(prompt, max_new_tokens=150)\n","    reply = reply.split(\"User:\")[0].strip()\n","\n","    st.chat_message(\"assistant\").markdown(reply)\n","    st.session_state.chat_history.append((\"assistant\", reply))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LQ8dLQ1weEdL","executionInfo":{"status":"ok","timestamp":1749235308357,"user_tz":240,"elapsed":20,"user":{"displayName":"Yu-Hui Lien","userId":"16304015909641248327"}},"outputId":"0cfadef6-fabf-4787-d101-b2a577bd84a6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","source":["!npm install localtunnel\n","!streamlit run app.py --server.address=localhost &>/content/logs.txt &\n","!npx localtunnel --port 8501 & curl https://loca.lt/mytunnelpassword"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHIbpMV4MN7M","executionInfo":{"status":"ok","timestamp":1749235792408,"user_tz":240,"elapsed":480531,"user":{"displayName":"Yu-Hui Lien","userId":"16304015909641248327"}},"outputId":"2e92ed5a-f83e-4708-d04c-c57979a99ffc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K\n","added 22 packages in 1s\n","\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K\n","\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K3 packages are looking for funding\n","\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K  run `npm fund` for details\n","\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K35.194.239.179your url is: https://slick-donkeys-hammer.loca.lt\n"]}]},{"cell_type":"code","source":["!pip show streamlit\n","!pip show ctransformers"],"metadata":{"id":"d7RvD-vK2hK0","executionInfo":{"status":"ok","timestamp":1749257168386,"user_tz":240,"elapsed":3048,"user":{"displayName":"Yu-Hui Lien","userId":"16304015909641248327"}},"outputId":"75183f6d-3f23-4ee0-c1cd-8a3865c893ed","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: streamlit\n","Version: 1.45.1\n","Summary: A faster way to build and share data apps\n","Home-page: https://streamlit.io\n","Author: Snowflake Inc\n","Author-email: hello@streamlit.io\n","License: Apache License 2.0\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: altair, blinker, cachetools, click, gitpython, numpy, packaging, pandas, pillow, protobuf, pyarrow, pydeck, requests, tenacity, toml, tornado, typing-extensions, watchdog\n","Required-by: \n","Name: ctransformers\n","Version: 0.2.27\n","Summary: Python bindings for the Transformer models implemented in C/C++ using GGML library.\n","Home-page: https://github.com/marella/ctransformers\n","Author: Ravindra Marella\n","Author-email: mv.ravindra007@gmail.com\n","License: MIT\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: huggingface-hub, py-cpuinfo\n","Required-by: \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"K10No0X_2hnG"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"12dur3J9VmesnlVooamHRDMj5ddgucBa-","timestamp":1749235061748}],"machine_shape":"hm","authorship_tag":"ABX9TyOzcu+ZQJJuxuBNP56UAM8N"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}